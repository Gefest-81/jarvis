{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import jarvis\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where do I start? Summarize current and past experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:11<00:00,  5.51s/it]\n"
     ]
    }
   ],
   "source": [
    "summary = jarvis.listVersionSummaries('twitter_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c01502400e82d88fffa8a1988085fa04421e2dd2',\n",
       "     __trialNum__  alpha  frac       model  model_accuracy  split_seed\n",
       "  0             9    0.9  0.75  NOT LOADED         0.58152          42\n",
       "  1             0    0.0  0.75  NOT LOADED         0.79514          42\n",
       "  2             7    0.7  0.75  NOT LOADED         0.60018          42\n",
       "  3             6    0.6  0.75  NOT LOADED         0.61348          42\n",
       "  4             1    0.1  0.75  NOT LOADED         0.73202          42\n",
       "  5            10    1.0  0.75  NOT LOADED         0.57407          42\n",
       "  6             8    0.8  0.75  NOT LOADED         0.58993          42\n",
       "  7             4    0.4  0.75  NOT LOADED         0.64544          42\n",
       "  8             3    0.3  0.75  NOT LOADED         0.66530          42\n",
       "  9             2    0.2  0.75  NOT LOADED         0.69506          42\n",
       "  10            5    0.5  0.75  NOT LOADED         0.62654          42),\n",
       " ('597cb760c89b1db5b3efd26c981539fffe79bb83',\n",
       "     __trialNum__  alpha  frac       model  model_accuracy  split_seed\n",
       "  0             9    0.9  0.75  NOT LOADED         0.67365          42\n",
       "  1             0    0.0  0.75  NOT LOADED         0.78794          42\n",
       "  2             7    0.7  0.75  NOT LOADED         0.68836          42\n",
       "  3             6    0.6  0.75  NOT LOADED         0.69476          42\n",
       "  4             1    0.1  0.75  NOT LOADED         0.76483          42\n",
       "  5            10    1.0  0.75  NOT LOADED         0.66765          42\n",
       "  6             8    0.8  0.75  NOT LOADED         0.68210          42\n",
       "  7             4    0.4  0.75  NOT LOADED         0.71461          42\n",
       "  8             3    0.3  0.75  NOT LOADED         0.73027          42\n",
       "  9             2    0.2  0.75  NOT LOADED         0.74567          42\n",
       "  10            5    0.5  0.75  NOT LOADED         0.70406          42)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the best experiment?\n",
    "Here, we measure _goodness_ of an experiment by its average model accuracy, over all trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c01502400e82d88fffa8a1988085fa04421e2dd2', 0.6471527272727273),\n",
       " ('597cb760c89b1db5b3efd26c981539fffe79bb83', 0.713990909090909)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stat = list(map(lambda x: (x[0], x[1]['model_accuracy'].mean()), summary))\n",
    "summary_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'597cb760c89b1db5b3efd26c981539fffe79bb83'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stat_df = pd.DataFrame(summary_stat)\n",
    "best_index = summary_stat_df.iloc[:, 1].idxmax()\n",
    "best_commit_hash = summary_stat_df.iloc[1, 0]\n",
    "best_commit_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the best trial, given the best experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xp_df = list(filter(lambda x: x[0] == best_commit_hash, summary))[0][1]\n",
    "best_trial = best_xp_df.iloc[best_xp_df['model_accuracy'].idxmax()]['__trialNum__']\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So the former experiment is better than the latter. What changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = list(map(lambda x: x[0], summary))\n",
    "most_recent, least_recent = versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;30mtrain_model.py --> train_model.py\n",
      "\u001b[0;30m@@ -47,8 +47,8 @@ def train(tweet_df, alpha):\n",
      "\u001b[0;30m     ## Convert tweet to bag of words for learning\n",
      "\u001b[0;30m \n",
      "\u001b[0;30m     # Tokenize Text\n",
      "\u001b[1;31m-    count_vect = CountVectorizer()\n",
      "\u001b[1;31m-    #count_vect = TfidfVectorizer()\n",
      "\u001b[1;32m+    #count_vect = CountVectorizer()\n",
      "\u001b[1;32m+    count_vect = TfidfVectorizer()\n",
      "\u001b[0;30m     X_train = count_vect.fit_transform(tweet_df[\"tweet\"])\n",
      "\u001b[0;30m \n",
      "\u001b[0;30m     intermediary[\"vectorizer\"] = count_vect\n"
     ]
    }
   ],
   "source": [
    "jarvis.diffExperimentVersions('twitter_demo', least_recent, most_recent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get the best model yet!\n",
    "From the best trial, from the best experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_intermediary = jarvis.materialize('twitter_demo', best_trial, best_commit_hash, 'intermediary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': MultinomialNB(alpha=0.0, class_prior=None, fit_prior=True),\n",
       " 'country_dict': {' ': 32,\n",
       "  ' AD': 21,\n",
       "  ' AE': 105,\n",
       "  ' AF': 15,\n",
       "  ' AG': 119,\n",
       "  ' AI': 106,\n",
       "  ' AL': 155,\n",
       "  ' AM': 148,\n",
       "  ' AO': 25,\n",
       "  ' AR': 11,\n",
       "  ' AT': 62,\n",
       "  ' AU': 55,\n",
       "  ' AW': 66,\n",
       "  ' AZ': 77,\n",
       "  ' BA': 92,\n",
       "  ' BB': 79,\n",
       "  ' BD': 28,\n",
       "  ' BE': 149,\n",
       "  ' BG': 29,\n",
       "  ' BH': 157,\n",
       "  ' BI': 150,\n",
       "  ' BJ': 12,\n",
       "  ' BM': 98,\n",
       "  ' BN': 18,\n",
       "  ' BO': 53,\n",
       "  ' BQ': 156,\n",
       "  ' BR': 97,\n",
       "  ' BS': 9,\n",
       "  ' BW': 91,\n",
       "  ' BY': 7,\n",
       "  ' CA': 50,\n",
       "  ' CD': 162,\n",
       "  ' CG': 90,\n",
       "  ' CH': 59,\n",
       "  ' CI': 40,\n",
       "  ' CL': 22,\n",
       "  ' CM': 121,\n",
       "  ' CN': 36,\n",
       "  ' CO': 100,\n",
       "  ' CR': 76,\n",
       "  ' CU': 102,\n",
       "  ' CV': 96,\n",
       "  ' CY': 74,\n",
       "  ' CZ': 116,\n",
       "  ' DE': 169,\n",
       "  ' DK': 34,\n",
       "  ' DM': 109,\n",
       "  ' DO': 137,\n",
       "  ' DZ': 115,\n",
       "  ' EC': 111,\n",
       "  ' EE': 80,\n",
       "  ' EG': 85,\n",
       "  ' ES': 163,\n",
       "  ' ET': 142,\n",
       "  ' FI': 67,\n",
       "  ' FR': 78,\n",
       "  ' GA': 112,\n",
       "  ' GB': 30,\n",
       "  ' GE': 138,\n",
       "  ' GH': 145,\n",
       "  ' GI': 56,\n",
       "  ' GL': 173,\n",
       "  ' GN': 108,\n",
       "  ' GP': 143,\n",
       "  ' GR': 172,\n",
       "  ' GT': 19,\n",
       "  ' GU': 14,\n",
       "  ' GY': 63,\n",
       "  ' HK': 164,\n",
       "  ' HN': 42,\n",
       "  ' HR': 170,\n",
       "  ' HT': 127,\n",
       "  ' HU': 75,\n",
       "  ' ID': 35,\n",
       "  ' IE': 57,\n",
       "  ' IL': 131,\n",
       "  ' IM': 17,\n",
       "  ' IN': 26,\n",
       "  ' IQ': 168,\n",
       "  ' IR': 144,\n",
       "  ' IS': 51,\n",
       "  ' IT': 58,\n",
       "  ' JE': 48,\n",
       "  ' JM': 24,\n",
       "  ' JO': 146,\n",
       "  ' JP': 179,\n",
       "  ' KE': 44,\n",
       "  ' KG': 125,\n",
       "  ' KH': 165,\n",
       "  ' KR': 38,\n",
       "  ' KW': 73,\n",
       "  ' KY': 37,\n",
       "  ' KZ': 151,\n",
       "  ' LB': 52,\n",
       "  ' LC': 94,\n",
       "  ' LK': 64,\n",
       "  ' LR': 84,\n",
       "  ' LS': 160,\n",
       "  ' LT': 87,\n",
       "  ' LU': 10,\n",
       "  ' LV': 140,\n",
       "  ' LY': 154,\n",
       "  ' MA': 8,\n",
       "  ' MC': 133,\n",
       "  ' MD': 23,\n",
       "  ' ME': 174,\n",
       "  ' MG': 65,\n",
       "  ' MK': 147,\n",
       "  ' MM': 135,\n",
       "  ' MO': 120,\n",
       "  ' MQ': 166,\n",
       "  ' MT': 88,\n",
       "  ' MU': 81,\n",
       "  ' MV': 177,\n",
       "  ' MW': 130,\n",
       "  ' MX': 139,\n",
       "  ' MY': 82,\n",
       "  ' MZ': 159,\n",
       "  ' NA': 175,\n",
       "  ' NE': 41,\n",
       "  ' NG': 103,\n",
       "  ' NI': 153,\n",
       "  ' NL': 4,\n",
       "  ' NO': 167,\n",
       "  ' NZ': 104,\n",
       "  ' OM': 158,\n",
       "  ' PA': 60,\n",
       "  ' PE': 69,\n",
       "  ' PF': 123,\n",
       "  ' PH': 54,\n",
       "  ' PK': 72,\n",
       "  ' PL': 107,\n",
       "  ' PR': 124,\n",
       "  ' PT': 178,\n",
       "  ' PY': 89,\n",
       "  ' QA': 27,\n",
       "  ' RE': 171,\n",
       "  ' RO': 86,\n",
       "  ' RS': 141,\n",
       "  ' RU': 95,\n",
       "  ' RW': 118,\n",
       "  ' SA': 128,\n",
       "  ' SD': 161,\n",
       "  ' SE': 6,\n",
       "  ' SG': 93,\n",
       "  ' SI': 49,\n",
       "  ' SK': 126,\n",
       "  ' SL': 61,\n",
       "  ' SN': 70,\n",
       "  ' SO': 16,\n",
       "  ' SV': 71,\n",
       "  ' SY': 33,\n",
       "  ' TC': 99,\n",
       "  ' TG': 45,\n",
       "  ' TH': 176,\n",
       "  ' TN': 134,\n",
       "  ' TR': 13,\n",
       "  ' TT': 43,\n",
       "  ' TW': 101,\n",
       "  ' TZ': 113,\n",
       "  ' UA': 152,\n",
       "  ' UG': 122,\n",
       "  ' US': 83,\n",
       "  ' UY': 136,\n",
       "  ' VA': 47,\n",
       "  ' VC': 31,\n",
       "  ' VE': 114,\n",
       "  ' VI': 5,\n",
       "  ' VN': 129,\n",
       "  ' WS': 68,\n",
       "  ' XK': 110,\n",
       "  ' YE': 20,\n",
       "  ' YT': 39,\n",
       "  ' ZA': 46,\n",
       "  ' ZM': 117,\n",
       "  ' ZW': 132,\n",
       "  nan: 0,\n",
       "  nan: 1,\n",
       "  nan: 2,\n",
       "  nan: 3},\n",
       " 'vectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=None, vocabulary=None)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_intermediary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's the best model in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's on your mind? OMG This works!! :D\n",
      "Predicted country of origin:  US\n",
      "\n",
      "What's on your mind? exit\n"
     ]
    }
   ],
   "source": [
    "country_dict = best_intermediary['country_dict']\n",
    "classifier = best_intermediary['classifier']\n",
    "vectorizer = best_intermediary['vectorizer']\n",
    "\n",
    "code_dict = {}\n",
    "\n",
    "for kee in country_dict:\n",
    "    code_dict[country_dict[kee]] = kee\n",
    "\n",
    "while True:\n",
    "    tweet = input(\"What's on your mind? \")\n",
    "    if tweet == 'exit':\n",
    "        break\n",
    "    tweet_vec = vectorizer.transform(np.array([tweet,]))\n",
    "    country_id = classifier.predict(tweet_vec)\n",
    "    print(\"Predicted country of origin: {}\\n\".format(code_dict[country_id[0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
