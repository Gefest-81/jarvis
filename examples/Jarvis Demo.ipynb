{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import jarvis\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where do I start? Summarize current and past experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.16s/it]\n"
     ]
    }
   ],
   "source": [
    "summary = jarvis.listVersionSummaries('twitter_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__trialNum__</th>\n",
       "      <th>alpha</th>\n",
       "      <th>frac</th>\n",
       "      <th>model</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>split_seed</th>\n",
       "      <th>__commitHash__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.58152</td>\n",
       "      <td>42</td>\n",
       "      <td>c01502400e82d88fffa8a1988085fa04421e2dd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.79514</td>\n",
       "      <td>42</td>\n",
       "      <td>c01502400e82d88fffa8a1988085fa04421e2dd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.60018</td>\n",
       "      <td>42</td>\n",
       "      <td>c01502400e82d88fffa8a1988085fa04421e2dd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.61348</td>\n",
       "      <td>42</td>\n",
       "      <td>c01502400e82d88fffa8a1988085fa04421e2dd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.73202</td>\n",
       "      <td>42</td>\n",
       "      <td>c01502400e82d88fffa8a1988085fa04421e2dd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.57407</td>\n",
       "      <td>42</td>\n",
       "      <td>c01502400e82d88fffa8a1988085fa04421e2dd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.58993</td>\n",
       "      <td>42</td>\n",
       "      <td>c01502400e82d88fffa8a1988085fa04421e2dd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.64544</td>\n",
       "      <td>42</td>\n",
       "      <td>c01502400e82d88fffa8a1988085fa04421e2dd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.66530</td>\n",
       "      <td>42</td>\n",
       "      <td>c01502400e82d88fffa8a1988085fa04421e2dd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.69506</td>\n",
       "      <td>42</td>\n",
       "      <td>c01502400e82d88fffa8a1988085fa04421e2dd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.62654</td>\n",
       "      <td>42</td>\n",
       "      <td>c01502400e82d88fffa8a1988085fa04421e2dd2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.67365</td>\n",
       "      <td>42</td>\n",
       "      <td>597cb760c89b1db5b3efd26c981539fffe79bb83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.78794</td>\n",
       "      <td>42</td>\n",
       "      <td>597cb760c89b1db5b3efd26c981539fffe79bb83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.68836</td>\n",
       "      <td>42</td>\n",
       "      <td>597cb760c89b1db5b3efd26c981539fffe79bb83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.69476</td>\n",
       "      <td>42</td>\n",
       "      <td>597cb760c89b1db5b3efd26c981539fffe79bb83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.76483</td>\n",
       "      <td>42</td>\n",
       "      <td>597cb760c89b1db5b3efd26c981539fffe79bb83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.66765</td>\n",
       "      <td>42</td>\n",
       "      <td>597cb760c89b1db5b3efd26c981539fffe79bb83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.68210</td>\n",
       "      <td>42</td>\n",
       "      <td>597cb760c89b1db5b3efd26c981539fffe79bb83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.71461</td>\n",
       "      <td>42</td>\n",
       "      <td>597cb760c89b1db5b3efd26c981539fffe79bb83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.73027</td>\n",
       "      <td>42</td>\n",
       "      <td>597cb760c89b1db5b3efd26c981539fffe79bb83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.74567</td>\n",
       "      <td>42</td>\n",
       "      <td>597cb760c89b1db5b3efd26c981539fffe79bb83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NOT LOADED</td>\n",
       "      <td>0.70406</td>\n",
       "      <td>42</td>\n",
       "      <td>597cb760c89b1db5b3efd26c981539fffe79bb83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   __trialNum__  alpha  frac       model  model_accuracy  split_seed  \\\n",
       "0             9    0.9  0.75  NOT LOADED         0.58152          42   \n",
       "1             0    0.0  0.75  NOT LOADED         0.79514          42   \n",
       "2             7    0.7  0.75  NOT LOADED         0.60018          42   \n",
       "3             6    0.6  0.75  NOT LOADED         0.61348          42   \n",
       "4             1    0.1  0.75  NOT LOADED         0.73202          42   \n",
       "5            10    1.0  0.75  NOT LOADED         0.57407          42   \n",
       "6             8    0.8  0.75  NOT LOADED         0.58993          42   \n",
       "7             4    0.4  0.75  NOT LOADED         0.64544          42   \n",
       "8             3    0.3  0.75  NOT LOADED         0.66530          42   \n",
       "9             2    0.2  0.75  NOT LOADED         0.69506          42   \n",
       "10            5    0.5  0.75  NOT LOADED         0.62654          42   \n",
       "11            9    0.9  0.75  NOT LOADED         0.67365          42   \n",
       "12            0    0.0  0.75  NOT LOADED         0.78794          42   \n",
       "13            7    0.7  0.75  NOT LOADED         0.68836          42   \n",
       "14            6    0.6  0.75  NOT LOADED         0.69476          42   \n",
       "15            1    0.1  0.75  NOT LOADED         0.76483          42   \n",
       "16           10    1.0  0.75  NOT LOADED         0.66765          42   \n",
       "17            8    0.8  0.75  NOT LOADED         0.68210          42   \n",
       "18            4    0.4  0.75  NOT LOADED         0.71461          42   \n",
       "19            3    0.3  0.75  NOT LOADED         0.73027          42   \n",
       "20            2    0.2  0.75  NOT LOADED         0.74567          42   \n",
       "21            5    0.5  0.75  NOT LOADED         0.70406          42   \n",
       "\n",
       "                              __commitHash__  \n",
       "0   c01502400e82d88fffa8a1988085fa04421e2dd2  \n",
       "1   c01502400e82d88fffa8a1988085fa04421e2dd2  \n",
       "2   c01502400e82d88fffa8a1988085fa04421e2dd2  \n",
       "3   c01502400e82d88fffa8a1988085fa04421e2dd2  \n",
       "4   c01502400e82d88fffa8a1988085fa04421e2dd2  \n",
       "5   c01502400e82d88fffa8a1988085fa04421e2dd2  \n",
       "6   c01502400e82d88fffa8a1988085fa04421e2dd2  \n",
       "7   c01502400e82d88fffa8a1988085fa04421e2dd2  \n",
       "8   c01502400e82d88fffa8a1988085fa04421e2dd2  \n",
       "9   c01502400e82d88fffa8a1988085fa04421e2dd2  \n",
       "10  c01502400e82d88fffa8a1988085fa04421e2dd2  \n",
       "11  597cb760c89b1db5b3efd26c981539fffe79bb83  \n",
       "12  597cb760c89b1db5b3efd26c981539fffe79bb83  \n",
       "13  597cb760c89b1db5b3efd26c981539fffe79bb83  \n",
       "14  597cb760c89b1db5b3efd26c981539fffe79bb83  \n",
       "15  597cb760c89b1db5b3efd26c981539fffe79bb83  \n",
       "16  597cb760c89b1db5b3efd26c981539fffe79bb83  \n",
       "17  597cb760c89b1db5b3efd26c981539fffe79bb83  \n",
       "18  597cb760c89b1db5b3efd26c981539fffe79bb83  \n",
       "19  597cb760c89b1db5b3efd26c981539fffe79bb83  \n",
       "20  597cb760c89b1db5b3efd26c981539fffe79bb83  \n",
       "21  597cb760c89b1db5b3efd26c981539fffe79bb83  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the best experiment?\n",
    "Here, we measure _goodness_ of an experiment by its average model accuracy, over all trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__commitHash__\n",
       "597cb760c89b1db5b3efd26c981539fffe79bb83    0.713991\n",
       "c01502400e82d88fffa8a1988085fa04421e2dd2    0.647153\n",
       "Name: model_accuracy, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stat = summary.groupby('__commitHash__')['model_accuracy'].mean()\n",
    "summary_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'597cb760c89b1db5b3efd26c981539fffe79bb83'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_commit_hash = summary_stat.idxmax()\n",
    "best_commit_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the best trial, given the best experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index = summary.loc[summary['__commitHash__'] == best_commit_hash]['model_accuracy'].idxmax()\n",
    "best_trial = summary.iloc[best_index]['__trialNum__']\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So the former experiment is better than the latter. What changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = summary.__commitHash__.unique()\n",
    "most_recent, least_recent = versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;30mtrain_model.py --> train_model.py\n",
      "\u001b[0;30m@@ -47,8 +47,8 @@ def train(tweet_df, alpha):\n",
      "\u001b[0;30m     ## Convert tweet to bag of words for learning\n",
      "\u001b[0;30m \n",
      "\u001b[0;30m     # Tokenize Text\n",
      "\u001b[1;31m-    count_vect = CountVectorizer()\n",
      "\u001b[1;31m-    #count_vect = TfidfVectorizer()\n",
      "\u001b[1;32m+    #count_vect = CountVectorizer()\n",
      "\u001b[1;32m+    count_vect = TfidfVectorizer()\n",
      "\u001b[0;30m     X_train = count_vect.fit_transform(tweet_df[\"tweet\"])\n",
      "\u001b[0;30m \n",
      "\u001b[0;30m     intermediary[\"vectorizer\"] = count_vect\n"
     ]
    }
   ],
   "source": [
    "jarvis.diffExperimentVersions('twitter_demo', least_recent, most_recent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get the best model yet!\n",
    "From the best trial, from the best experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_intermediary = jarvis.materialize('twitter_demo', best_trial, best_commit_hash, 'intermediary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': MultinomialNB(alpha=0.0, class_prior=None, fit_prior=True),\n",
       " 'country_dict': {' ': 32,\n",
       "  ' AD': 21,\n",
       "  ' AE': 105,\n",
       "  ' AF': 15,\n",
       "  ' AG': 119,\n",
       "  ' AI': 106,\n",
       "  ' AL': 155,\n",
       "  ' AM': 148,\n",
       "  ' AO': 25,\n",
       "  ' AR': 11,\n",
       "  ' AT': 62,\n",
       "  ' AU': 55,\n",
       "  ' AW': 66,\n",
       "  ' AZ': 77,\n",
       "  ' BA': 92,\n",
       "  ' BB': 79,\n",
       "  ' BD': 28,\n",
       "  ' BE': 149,\n",
       "  ' BG': 29,\n",
       "  ' BH': 157,\n",
       "  ' BI': 150,\n",
       "  ' BJ': 12,\n",
       "  ' BM': 98,\n",
       "  ' BN': 18,\n",
       "  ' BO': 53,\n",
       "  ' BQ': 156,\n",
       "  ' BR': 97,\n",
       "  ' BS': 9,\n",
       "  ' BW': 91,\n",
       "  ' BY': 7,\n",
       "  ' CA': 50,\n",
       "  ' CD': 162,\n",
       "  ' CG': 90,\n",
       "  ' CH': 59,\n",
       "  ' CI': 40,\n",
       "  ' CL': 22,\n",
       "  ' CM': 121,\n",
       "  ' CN': 36,\n",
       "  ' CO': 100,\n",
       "  ' CR': 76,\n",
       "  ' CU': 102,\n",
       "  ' CV': 96,\n",
       "  ' CY': 74,\n",
       "  ' CZ': 116,\n",
       "  ' DE': 169,\n",
       "  ' DK': 34,\n",
       "  ' DM': 109,\n",
       "  ' DO': 137,\n",
       "  ' DZ': 115,\n",
       "  ' EC': 111,\n",
       "  ' EE': 80,\n",
       "  ' EG': 85,\n",
       "  ' ES': 163,\n",
       "  ' ET': 142,\n",
       "  ' FI': 67,\n",
       "  ' FR': 78,\n",
       "  ' GA': 112,\n",
       "  ' GB': 30,\n",
       "  ' GE': 138,\n",
       "  ' GH': 145,\n",
       "  ' GI': 56,\n",
       "  ' GL': 173,\n",
       "  ' GN': 108,\n",
       "  ' GP': 143,\n",
       "  ' GR': 172,\n",
       "  ' GT': 19,\n",
       "  ' GU': 14,\n",
       "  ' GY': 63,\n",
       "  ' HK': 164,\n",
       "  ' HN': 42,\n",
       "  ' HR': 170,\n",
       "  ' HT': 127,\n",
       "  ' HU': 75,\n",
       "  ' ID': 35,\n",
       "  ' IE': 57,\n",
       "  ' IL': 131,\n",
       "  ' IM': 17,\n",
       "  ' IN': 26,\n",
       "  ' IQ': 168,\n",
       "  ' IR': 144,\n",
       "  ' IS': 51,\n",
       "  ' IT': 58,\n",
       "  ' JE': 48,\n",
       "  ' JM': 24,\n",
       "  ' JO': 146,\n",
       "  ' JP': 179,\n",
       "  ' KE': 44,\n",
       "  ' KG': 125,\n",
       "  ' KH': 165,\n",
       "  ' KR': 38,\n",
       "  ' KW': 73,\n",
       "  ' KY': 37,\n",
       "  ' KZ': 151,\n",
       "  ' LB': 52,\n",
       "  ' LC': 94,\n",
       "  ' LK': 64,\n",
       "  ' LR': 84,\n",
       "  ' LS': 160,\n",
       "  ' LT': 87,\n",
       "  ' LU': 10,\n",
       "  ' LV': 140,\n",
       "  ' LY': 154,\n",
       "  ' MA': 8,\n",
       "  ' MC': 133,\n",
       "  ' MD': 23,\n",
       "  ' ME': 174,\n",
       "  ' MG': 65,\n",
       "  ' MK': 147,\n",
       "  ' MM': 135,\n",
       "  ' MO': 120,\n",
       "  ' MQ': 166,\n",
       "  ' MT': 88,\n",
       "  ' MU': 81,\n",
       "  ' MV': 177,\n",
       "  ' MW': 130,\n",
       "  ' MX': 139,\n",
       "  ' MY': 82,\n",
       "  ' MZ': 159,\n",
       "  ' NA': 175,\n",
       "  ' NE': 41,\n",
       "  ' NG': 103,\n",
       "  ' NI': 153,\n",
       "  ' NL': 4,\n",
       "  ' NO': 167,\n",
       "  ' NZ': 104,\n",
       "  ' OM': 158,\n",
       "  ' PA': 60,\n",
       "  ' PE': 69,\n",
       "  ' PF': 123,\n",
       "  ' PH': 54,\n",
       "  ' PK': 72,\n",
       "  ' PL': 107,\n",
       "  ' PR': 124,\n",
       "  ' PT': 178,\n",
       "  ' PY': 89,\n",
       "  ' QA': 27,\n",
       "  ' RE': 171,\n",
       "  ' RO': 86,\n",
       "  ' RS': 141,\n",
       "  ' RU': 95,\n",
       "  ' RW': 118,\n",
       "  ' SA': 128,\n",
       "  ' SD': 161,\n",
       "  ' SE': 6,\n",
       "  ' SG': 93,\n",
       "  ' SI': 49,\n",
       "  ' SK': 126,\n",
       "  ' SL': 61,\n",
       "  ' SN': 70,\n",
       "  ' SO': 16,\n",
       "  ' SV': 71,\n",
       "  ' SY': 33,\n",
       "  ' TC': 99,\n",
       "  ' TG': 45,\n",
       "  ' TH': 176,\n",
       "  ' TN': 134,\n",
       "  ' TR': 13,\n",
       "  ' TT': 43,\n",
       "  ' TW': 101,\n",
       "  ' TZ': 113,\n",
       "  ' UA': 152,\n",
       "  ' UG': 122,\n",
       "  ' US': 83,\n",
       "  ' UY': 136,\n",
       "  ' VA': 47,\n",
       "  ' VC': 31,\n",
       "  ' VE': 114,\n",
       "  ' VI': 5,\n",
       "  ' VN': 129,\n",
       "  ' WS': 68,\n",
       "  ' XK': 110,\n",
       "  ' YE': 20,\n",
       "  ' YT': 39,\n",
       "  ' ZA': 46,\n",
       "  ' ZM': 117,\n",
       "  ' ZW': 132,\n",
       "  nan: 0,\n",
       "  nan: 1,\n",
       "  nan: 2,\n",
       "  nan: 3},\n",
       " 'vectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=None, vocabulary=None)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_intermediary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's the best model in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's on your mind? OMG this works!! :D\n",
      "Predicted country of origin:  US\n",
      "\n",
      "What's on your mind? exit\n"
     ]
    }
   ],
   "source": [
    "country_dict = best_intermediary['country_dict']\n",
    "classifier = best_intermediary['classifier']\n",
    "vectorizer = best_intermediary['vectorizer']\n",
    "\n",
    "code_dict = {}\n",
    "\n",
    "for kee in country_dict:\n",
    "    code_dict[country_dict[kee]] = kee\n",
    "\n",
    "while True:\n",
    "    tweet = input(\"What's on your mind? \")\n",
    "    if tweet == 'exit':\n",
    "        break\n",
    "    tweet_vec = vectorizer.transform(np.array([tweet,]))\n",
    "    country_id = classifier.predict(tweet_vec)\n",
    "    print(\"Predicted country of origin: {}\\n\".format(code_dict[country_id[0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
