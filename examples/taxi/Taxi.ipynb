{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jarvis\n",
    "\n",
    "with jarvis.Experiment('taxi_demo') as ex:\n",
    "    \n",
    "    jarvis.setNotebookName('Taxi.ipynb')\n",
    "    \n",
    "    ex.groundClient('ground')\n",
    "\n",
    "    tr_data = ex.artifact('train_df.csv')\n",
    "\n",
    "    tr_data2 = ex.artifact('train.csv')\n",
    "\n",
    "    te_data = ex.artifact('test_df.csv')\n",
    "\n",
    "    @jarvis.func\n",
    "    def dataframize(csvpath):\n",
    "        import pandas as pd\n",
    "        return pd.read_csv(csvpath)\n",
    "\n",
    "\n",
    "    do_dfize = ex.action(dataframize, [tr_data])\n",
    "\n",
    "    tr_data_df = ex.artifact('train_df.pkl', do_dfize)\n",
    "\n",
    "    @jarvis.func\n",
    "    def calculate_distance(data_df):\n",
    "        def manhattan_distance(x1, y1, x2, y2):\n",
    "            return abs(x1 - x2) + abs(y1 - y2)\n",
    "        data_df['distance'] = [ i for i in map(manhattan_distance, data_df['pickup_longitude'], data_df['pickup_latitude'], \n",
    "                                               data_df['dropoff_longitude'], data_df['dropoff_latitude'])]\n",
    "        return data_df\n",
    "\n",
    "    # Trimmed some Notebook Cells without losing the log.\n",
    "\n",
    "    # Other thing with Nb. variables continue to exist even after cell has been clipped.\n",
    "\n",
    "    do_calc_dist = ex.action(calculate_distance, [tr_data_df])\n",
    "    tr_data_dist_df = ex.artifact('train_dist_df.pkl', do_calc_dist)\n",
    "\n",
    "    @jarvis.func\n",
    "    def preproc(train_data):\n",
    "        import numpy as np\n",
    "        # https://www.kaggle.com/stephaniestallworth/nyc-taxi-eda-regression-fivethirtyeight-viz/notebook\n",
    "        train_data = train_data[train_data['passenger_count']>0]\n",
    "        train_data = train_data[train_data['passenger_count']<9]\n",
    "\n",
    "        # Remove coordinate outliers\n",
    "        train_data = train_data[train_data['pickup_longitude'] <= -73.75]\n",
    "        train_data = train_data[train_data['pickup_longitude'] >= -74.03]\n",
    "        train_data = train_data[train_data['pickup_latitude'] <= 40.85]\n",
    "        train_data = train_data[train_data['pickup_latitude'] >= 40.63]\n",
    "        train_data = train_data[train_data['dropoff_longitude'] <= -73.75]\n",
    "        train_data = train_data[train_data['dropoff_longitude'] >= -74.03]\n",
    "        train_data = train_data[train_data['dropoff_latitude'] <= 40.85]\n",
    "        train_data = train_data[train_data['dropoff_latitude'] >= 40.63]\n",
    "\n",
    "        # Remove trip_duration outliers\n",
    "        trip_duration_mean = np.mean(train_data['trip_duration'])\n",
    "        trip_duration_std = np.std(train_data['trip_duration'])\n",
    "        train_data = train_data[train_data['trip_duration']<=trip_duration_mean + 2*trip_duration_std]\n",
    "        train_data = train_data[train_data['trip_duration']>= trip_duration_mean - 2*trip_duration_std]\n",
    "        train_data = train_data[train_data['trip_duration'] >= 30]\n",
    "        train_data = train_data[train_data['trip_duration'] <= 60*240]\n",
    "\n",
    "        return train_data\n",
    "\n",
    "    do_preproc = ex.action(preproc, [tr_data_dist_df])\n",
    "    tr_ready = ex.artifact('train_ready.pkl', do_preproc)\n",
    "\n",
    "    @jarvis.func\n",
    "    def split(data_df):\n",
    "        X = data_df[['vendor_id', 'passenger_count', 'pickup_longitude',\n",
    "            'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "           'store_and_fwd_flag', 'pickup_datetime', 'distance']]\n",
    "        y = data_df['trip_duration']\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    do_split = ex.action(split, [tr_ready])\n",
    "    xTrain = ex.artifact('xTrain.pkl', do_split)\n",
    "    xTest = ex.artifact('xTest.pkl', do_split)\n",
    "    yTrain = ex.artifact('yTrain.pkl', do_split)\n",
    "    yTest = ex.artifact('yTest.pkl', do_split)\n",
    "\n",
    "    @jarvis.func\n",
    "    def train(data_df, trainingy):\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "        data_df['duration'] = trainingy\n",
    "\n",
    "        def roundtime(tstring):\n",
    "            hours, mins, secs = tstring.split(':')\n",
    "            if int(mins) >= 30:\n",
    "                if hours == '23':\n",
    "                    return '00'\n",
    "                else:\n",
    "                    return str(int(hours) + 1)\n",
    "            else:\n",
    "                return hours\n",
    "\n",
    "        def weekday(start):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp = datetime.strptime(start, fmt)\n",
    "            return int(tstamp.weekday())\n",
    "\n",
    "        data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "        data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "        data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "        import math\n",
    "\n",
    "        clf = RandomForestRegressor(n_estimators=20, n_jobs=3)\n",
    "        #clf = LinearRegression()\n",
    "        scaler = StandardScaler()\n",
    "        # Scaler does not help\n",
    "        #scaler.fit(data_df[['vendor_id', 'start_hr', 'start_month', 'start_weekday', 'distance']].values)\n",
    "        clf.fit(data_df[['vendor_id', 'start_hr', 'start_month', 'start_weekday', 'distance', \n",
    "                         'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "                        'dropoff_latitude']].values, data_df['duration'].values )\n",
    "        return clf, scaler\n",
    "\n",
    "    do_train = ex.action(train, [xTrain, yTrain])\n",
    "    model = ex.artifact('model.pkl', do_train)\n",
    "    scaler = ex.artifact('scaler.pkl', do_train)\n",
    "\n",
    "    do_te_dfize = ex.action(dataframize, [te_data])\n",
    "    te_data_df = ex.artifact('test_df.pkl', do_te_dfize)\n",
    "\n",
    "    do_te_calcdist = ex.action(calculate_distance, [te_data_df])\n",
    "    te_data_dist_df = ex.artifact('test_dist_df.pkl', do_te_calcdist)\n",
    "\n",
    "    @jarvis.func\n",
    "    def calculate_duration(data_df):\n",
    "        def tdiff(start, end):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp1 = datetime.strptime(start, fmt)\n",
    "            tstamp2 = datetime.strptime(end, fmt)\n",
    "\n",
    "            if tstamp1 > tstamp2:\n",
    "                td = tstamp1 - tstamp2\n",
    "            else:\n",
    "                td = tstamp2 - tstamp1\n",
    "            return int(td.total_seconds())\n",
    "        data_df['duration'] = [i for i in map(tdiff, data_df['pickup_datetime'], data_df['dropoff_datetime'])]\n",
    "        return data_df\n",
    "\n",
    "\n",
    "\n",
    "    do_te_calcdur = ex.action(calculate_duration, [te_data_dist_df])\n",
    "    te_data_full_df = ex.artifact('test_dist_dur_df.pkl', do_te_calcdur)\n",
    "\n",
    "    @jarvis.func\n",
    "    def test(model, data_df, testingy, scaler):\n",
    "        import numpy as np\n",
    "        data_df['duration'] = testingy\n",
    "        def roundtime(tstring):\n",
    "            hours, mins, secs = tstring.split(':')\n",
    "            if int(mins) >= 30:\n",
    "                if hours == '23':\n",
    "                    return '00'\n",
    "                else:\n",
    "                    return str(int(hours) + 1)\n",
    "            else:\n",
    "                return hours\n",
    "        def weekday(start):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp = datetime.strptime(start, fmt)\n",
    "            return int(tstamp.weekday())\n",
    "\n",
    "        data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "        data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "        data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "\n",
    "        preds = model.predict(data_df[['vendor_id', 'start_hr', 'start_month', 'start_weekday', 'distance', \n",
    "                         'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "                        'dropoff_latitude']].values)\n",
    "        from sklearn import metrics\n",
    "        import math\n",
    "        score = metrics.explained_variance_score(data_df['duration'].values, preds)\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(data_df['duration'].values, preds))\n",
    "        return str(score) + '\\n' + str(rmse)\n",
    "\n",
    "\n",
    "    do_test = ex.action(test, [model, xTest, yTest, scaler])\n",
    "    score = ex.artifact('score.txt', do_test)\n",
    "\n",
    "    @jarvis.func\n",
    "    def comp_predictions(model, data_df, scaler):\n",
    "        def roundtime(tstring):\n",
    "            hours, mins, secs = tstring.split(':')\n",
    "            if int(mins) >= 30:\n",
    "                if hours == '23':\n",
    "                    return '00'\n",
    "                else:\n",
    "                    return str(int(hours) + 1)\n",
    "            else:\n",
    "                return hours\n",
    "        def weekday(start):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp = datetime.strptime(start, fmt)\n",
    "            return int(tstamp.weekday())\n",
    "\n",
    "        data_df['start_hr'] = data_df['start_timestamp'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "        data_df['start_month'] = data_df['start_timestamp'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "        data_df['start_weekday']= data_df['start_timestamp'].apply(lambda x: weekday(x))\n",
    "\n",
    "        predictions = (model.predict(data_df[['start_hr', 'start_month', 'start_weekday', 'distance']].values), data_df['duration'])\n",
    "        return predictions\n",
    "\n",
    "    do_comp = ex.action(comp_predictions, [model, te_data_full_df, scaler])\n",
    "    preds = ex.artifact('predictions.pkl', do_comp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id,vendor_id,start_timestamp,end_timestamp,passenger_count,start_lng,start_lat,end_lng,end_lat,store_and_fwd_flag,duration\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data.peek(head=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id,vendor_id,pickup_datetime,dropoff_datetime,passenger_count,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,store_and_fwd_flag,trip_duration\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data2.peek(head=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.7800057858579262\n",
      "RMSE: 302.9232106738426\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def manhattan_distance(x1, y1, x2, y2):\n",
    "    return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "def roundtime(tstring):\n",
    "    hours, mins, secs = tstring.split(':')\n",
    "    if int(mins) >= 30:\n",
    "        if hours == '23':\n",
    "            return '00'\n",
    "        else:\n",
    "            return str(int(hours) + 1)\n",
    "    else:\n",
    "        return hours\n",
    "\n",
    "def weekday(start):\n",
    "    from datetime import datetime\n",
    "    fmt = '%Y-%m-%d %H:%M:%S'\n",
    "    tstamp = datetime.strptime(start, fmt)\n",
    "    return int(tstamp.weekday())\n",
    "\n",
    "data_df = pd.read_csv('train.csv')\n",
    "\n",
    "data_df['distance'] = [i for i in map(manhattan_distance,\n",
    "    data_df['pickup_longitude'], data_df['pickup_latitude'], \n",
    "    data_df['dropoff_longitude'], data_df['dropoff_latitude'])]\n",
    "\n",
    "# Remove outliers in passenger_count\n",
    "data_df = data_df[data_df['passenger_count']>0]\n",
    "data_df = data_df[data_df['passenger_count']<9]\n",
    "\n",
    "# Remove coordinate outliers\n",
    "data_df = data_df[data_df['pickup_longitude'] <= -73.75]\n",
    "data_df = data_df[data_df['pickup_longitude'] >= -74.03]\n",
    "data_df = data_df[data_df['pickup_latitude'] <= 40.85]\n",
    "data_df = data_df[data_df['pickup_latitude'] >= 40.63]\n",
    "data_df = data_df[data_df['dropoff_longitude'] <= -73.75]\n",
    "data_df = data_df[data_df['dropoff_longitude'] >= -74.03]\n",
    "data_df = data_df[data_df['dropoff_latitude'] <= 40.85]\n",
    "data_df = data_df[data_df['dropoff_latitude'] >= 40.63]\n",
    "\n",
    "# Remove trip_duration outliers\n",
    "trip_duration_mean = np.mean(data_df['trip_duration'])\n",
    "trip_duration_std = np.std(data_df['trip_duration'])\n",
    "data_df = data_df[data_df['trip_duration'] <= trip_duration_mean + 2*trip_duration_std]\n",
    "data_df = data_df[data_df['trip_duration'] >= trip_duration_mean - 2*trip_duration_std]\n",
    "data_df = data_df[data_df['trip_duration'] >= 30]\n",
    "data_df = data_df[data_df['trip_duration'] <= 60*240]\n",
    "\n",
    "data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "X = data_df[['vendor_id', 'pickup_longitude',\n",
    "            'pickup_latitude', 'dropoff_longitude', \n",
    "            'dropoff_latitude', 'distance',\n",
    "            'start_hr', 'start_month', 'start_weekday']]\n",
    "y = data_df['trip_duration']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "    y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=20, n_jobs=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "score = metrics.explained_variance_score(y_test, preds)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "\n",
    "print(\"R2: {}\".format(score))\n",
    "print(\"RMSE: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import jarvis\n",
    "\n",
    "with jarvis.Experiment('taxi_coarse') as ex:\n",
    "    \n",
    "    jarvis.setNotebookName('Taxi.ipynb')\n",
    "    ex.groundClient('ground')\n",
    "    \n",
    "    @jarvis.func\n",
    "    def run_existing_pipeline(path_to_data):\n",
    "    \n",
    "        def manhattan_distance(x1, y1, x2, y2):\n",
    "            return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "        def roundtime(tstring):\n",
    "            hours, mins, secs = tstring.split(':')\n",
    "            if int(mins) >= 30:\n",
    "                if hours == '23':\n",
    "                    return '00'\n",
    "                else:\n",
    "                    return str(int(hours) + 1)\n",
    "            else:\n",
    "                return hours\n",
    "\n",
    "        def weekday(start):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp = datetime.strptime(start, fmt)\n",
    "            return int(tstamp.weekday())\n",
    "\n",
    "        data_df = pd.read_csv(path_to_data)\n",
    "\n",
    "        data_df['distance'] = [i for i in map(manhattan_distance,\n",
    "            data_df['pickup_longitude'], data_df['pickup_latitude'], \n",
    "            data_df['dropoff_longitude'], data_df['dropoff_latitude'])]\n",
    "\n",
    "        # Remove outliers in passenger_count\n",
    "        data_df = data_df[data_df['passenger_count']>0]\n",
    "        data_df = data_df[data_df['passenger_count']<9]\n",
    "\n",
    "        # Remove coordinate outliers\n",
    "        data_df = data_df[data_df['pickup_longitude'] <= -73.75]\n",
    "        data_df = data_df[data_df['pickup_longitude'] >= -74.03]\n",
    "        data_df = data_df[data_df['pickup_latitude'] <= 40.85]\n",
    "        data_df = data_df[data_df['pickup_latitude'] >= 40.63]\n",
    "        data_df = data_df[data_df['dropoff_longitude'] <= -73.75]\n",
    "        data_df = data_df[data_df['dropoff_longitude'] >= -74.03]\n",
    "        data_df = data_df[data_df['dropoff_latitude'] <= 40.85]\n",
    "        data_df = data_df[data_df['dropoff_latitude'] >= 40.63]\n",
    "\n",
    "        # Remove trip_duration outliers\n",
    "        trip_duration_mean = np.mean(data_df['trip_duration'])\n",
    "        trip_duration_std = np.std(data_df['trip_duration'])\n",
    "        data_df = data_df[data_df['trip_duration'] <= trip_duration_mean + 2*trip_duration_std]\n",
    "        data_df = data_df[data_df['trip_duration'] >= trip_duration_mean - 2*trip_duration_std]\n",
    "        data_df = data_df[data_df['trip_duration'] >= 30]\n",
    "        data_df = data_df[data_df['trip_duration'] <= 60*240]\n",
    "\n",
    "        data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "        data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "        data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "        X = data_df[['vendor_id', 'pickup_longitude',\n",
    "                    'pickup_latitude', 'dropoff_longitude', \n",
    "                    'dropoff_latitude', 'distance',\n",
    "                    'start_hr', 'start_month', 'start_weekday']]\n",
    "        y = data_df['trip_duration']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "            y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "        clf = RandomForestRegressor(n_estimators=20, n_jobs=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        preds = clf.predict(X_test)\n",
    "        score = metrics.explained_variance_score(y_test, preds)\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "\n",
    "        score = \"R2: {}\".format(score)\n",
    "        rmse = \"RMSE: {}\".format(rmse)\n",
    "        \n",
    "        print(score, rmse)\n",
    "    \n",
    "        return clf, score, rmse\n",
    "    \n",
    "    data = ex.artifact('train.csv')\n",
    "    do_all = ex.action(run_existing_pipeline, [data])\n",
    "    model = ex.artifact('model.pkl', do_all)\n",
    "    score = ex.artifact('score.txt', do_all)\n",
    "    rmse = ex.artifact('rmse.txt', do_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.779745741917466 RMSE: 303.1106087514103\n"
     ]
    }
   ],
   "source": [
    "score.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import jarvis\n",
    "\n",
    "with jarvis.Experiment('taxi_coarse') as ex:\n",
    "    \n",
    "    jarvis.setNotebookName('Taxi.ipynb')\n",
    "    ex.groundClient('ground')\n",
    "    \n",
    "    @jarvis.func\n",
    "    def run_existing_pipeline(path_to_data, n_estimators):\n",
    "    \n",
    "        def manhattan_distance(x1, y1, x2, y2):\n",
    "            return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "        def roundtime(tstring):\n",
    "            hours, mins, secs = tstring.split(':')\n",
    "            if int(mins) >= 30:\n",
    "                if hours == '23':\n",
    "                    return '00'\n",
    "                else:\n",
    "                    return str(int(hours) + 1)\n",
    "            else:\n",
    "                return hours\n",
    "\n",
    "        def weekday(start):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp = datetime.strptime(start, fmt)\n",
    "            return int(tstamp.weekday())\n",
    "\n",
    "        data_df = pd.read_csv(path_to_data)\n",
    "\n",
    "        data_df['distance'] = [i for i in map(manhattan_distance,\n",
    "            data_df['pickup_longitude'], data_df['pickup_latitude'], \n",
    "            data_df['dropoff_longitude'], data_df['dropoff_latitude'])]\n",
    "\n",
    "        # Remove outliers in passenger_count\n",
    "        data_df = data_df[data_df['passenger_count']>0]\n",
    "        data_df = data_df[data_df['passenger_count']<9]\n",
    "\n",
    "        # Remove coordinate outliers\n",
    "        data_df = data_df[data_df['pickup_longitude'] <= -73.75]\n",
    "        data_df = data_df[data_df['pickup_longitude'] >= -74.03]\n",
    "        data_df = data_df[data_df['pickup_latitude'] <= 40.85]\n",
    "        data_df = data_df[data_df['pickup_latitude'] >= 40.63]\n",
    "        data_df = data_df[data_df['dropoff_longitude'] <= -73.75]\n",
    "        data_df = data_df[data_df['dropoff_longitude'] >= -74.03]\n",
    "        data_df = data_df[data_df['dropoff_latitude'] <= 40.85]\n",
    "        data_df = data_df[data_df['dropoff_latitude'] >= 40.63]\n",
    "\n",
    "        # Remove trip_duration outliers\n",
    "        trip_duration_mean = np.mean(data_df['trip_duration'])\n",
    "        trip_duration_std = np.std(data_df['trip_duration'])\n",
    "        data_df = data_df[data_df['trip_duration'] <= trip_duration_mean + 2*trip_duration_std]\n",
    "        data_df = data_df[data_df['trip_duration'] >= trip_duration_mean - 2*trip_duration_std]\n",
    "        data_df = data_df[data_df['trip_duration'] >= 30]\n",
    "        data_df = data_df[data_df['trip_duration'] <= 60*240]\n",
    "\n",
    "        data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "        data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "        data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "        X = data_df[['vendor_id', 'pickup_longitude',\n",
    "                    'pickup_latitude', 'dropoff_longitude', \n",
    "                    'dropoff_latitude', 'distance',\n",
    "                    'start_hr', 'start_month', 'start_weekday']]\n",
    "        y = data_df['trip_duration']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "            y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "        clf = RandomForestRegressor(n_estimators=n_estimators, n_jobs=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        preds = clf.predict(X_test)\n",
    "        score = metrics.explained_variance_score(y_test, preds)\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "\n",
    "        score = \"R2: {}\".format(score)\n",
    "        rmse = \"RMSE: {}\".format(rmse)\n",
    "        \n",
    "        print(score, rmse)\n",
    "    \n",
    "        return clf, score, rmse\n",
    "    \n",
    "    data = ex.artifact('train.csv')\n",
    "    num_est = ex.literal([15, 20, 30], 'num_estimators')\n",
    "    num_est.forEach()\n",
    "    do_all = ex.action(run_existing_pipeline, [data, num_est])\n",
    "    model = ex.artifact('model.pkl', do_all)\n",
    "    score = ex.artifact('score.txt', do_all)\n",
    "    rmse = ex.artifact('rmse.txt', do_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.7748725843105921 RMSE: 306.43767227788436\n",
      "R2: 0.7791599274717955 RMSE: 303.49629696347023\n",
      "R2: 0.7834509576422817 RMSE: 300.54869927226036\n"
     ]
    }
   ],
   "source": [
    "score.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import jarvis\n",
    "\n",
    "with jarvis.Experiment('taxi_coarse') as ex:\n",
    "    \n",
    "    jarvis.setNotebookName('Taxi.ipynb')\n",
    "    ex.groundClient('ground')\n",
    "    \n",
    "    @jarvis.func\n",
    "    def prepare_data(path_to_data):\n",
    "    \n",
    "        def manhattan_distance(x1, y1, x2, y2):\n",
    "            return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "        def roundtime(tstring):\n",
    "            hours, mins, secs = tstring.split(':')\n",
    "            if int(mins) >= 30:\n",
    "                if hours == '23':\n",
    "                    return '00'\n",
    "                else:\n",
    "                    return str(int(hours) + 1)\n",
    "            else:\n",
    "                return hours\n",
    "\n",
    "        def weekday(start):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp = datetime.strptime(start, fmt)\n",
    "            return int(tstamp.weekday())\n",
    "\n",
    "        data_df = pd.read_csv(path_to_data)\n",
    "\n",
    "        data_df['distance'] = [i for i in map(manhattan_distance,\n",
    "            data_df['pickup_longitude'], data_df['pickup_latitude'], \n",
    "            data_df['dropoff_longitude'], data_df['dropoff_latitude'])]\n",
    "\n",
    "        # Remove outliers in passenger_count\n",
    "        data_df = data_df[data_df['passenger_count']>0]\n",
    "        data_df = data_df[data_df['passenger_count']<9]\n",
    "\n",
    "        # Remove coordinate outliers\n",
    "        data_df = data_df[data_df['pickup_longitude'] <= -73.75]\n",
    "        data_df = data_df[data_df['pickup_longitude'] >= -74.03]\n",
    "        data_df = data_df[data_df['pickup_latitude'] <= 40.85]\n",
    "        data_df = data_df[data_df['pickup_latitude'] >= 40.63]\n",
    "        data_df = data_df[data_df['dropoff_longitude'] <= -73.75]\n",
    "        data_df = data_df[data_df['dropoff_longitude'] >= -74.03]\n",
    "        data_df = data_df[data_df['dropoff_latitude'] <= 40.85]\n",
    "        data_df = data_df[data_df['dropoff_latitude'] >= 40.63]\n",
    "\n",
    "        # Remove trip_duration outliers\n",
    "        trip_duration_mean = np.mean(data_df['trip_duration'])\n",
    "        trip_duration_std = np.std(data_df['trip_duration'])\n",
    "        data_df = data_df[data_df['trip_duration'] <= trip_duration_mean + 2*trip_duration_std]\n",
    "        data_df = data_df[data_df['trip_duration'] >= trip_duration_mean - 2*trip_duration_std]\n",
    "        data_df = data_df[data_df['trip_duration'] >= 30]\n",
    "        data_df = data_df[data_df['trip_duration'] <= 60*240]\n",
    "\n",
    "        data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "        data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "        data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "        return data_df\n",
    "    \n",
    "    @jarvis.func\n",
    "    def train_test_model(data_df, n_estimators):\n",
    "        X = data_df[['vendor_id', 'pickup_longitude',\n",
    "                    'pickup_latitude', 'dropoff_longitude', \n",
    "                    'dropoff_latitude', 'distance',\n",
    "                    'start_hr', 'start_month', 'start_weekday']]\n",
    "        y = data_df['trip_duration']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "            y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "        clf = RandomForestRegressor(n_estimators=n_estimators, n_jobs=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        preds = clf.predict(X_test)\n",
    "        score = metrics.explained_variance_score(y_test, preds)\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "\n",
    "        score = \"R2: {}\".format(score)\n",
    "        rmse = \"RMSE: {}\".format(rmse)\n",
    "        \n",
    "        print(score, rmse)\n",
    "    \n",
    "        return clf, score, rmse\n",
    "    \n",
    "    data = ex.artifact('train.csv')\n",
    "    num_est = ex.literal([15, 20], 'num_estimators')\n",
    "    num_est.forEach()\n",
    "    \n",
    "    do_prep = ex.action(prepare_data, [data])\n",
    "    prepd = ex.artifact('prepped_data.pkl', do_prep)\n",
    "    \n",
    "    do_tr_te = ex.action(train_test_model, [prepd, num_est])\n",
    "\n",
    "    \n",
    "    model = ex.artifact('model.pkl', do_tr_te)\n",
    "    score = ex.artifact('score.txt', do_tr_te)\n",
    "    rmse = ex.artifact('rmse.txt', do_tr_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.7760128249160974 RMSE: 305.64950335540533\n",
      "R2: 0.7797606529016166 RMSE: 303.08540456623774\n"
     ]
    }
   ],
   "source": [
    "score.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
