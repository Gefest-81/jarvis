{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jarvis\n",
    "\n",
    "with jarvis.Experiment('taxi_demo') as ex:\n",
    "    \n",
    "    jarvis.setNotebookName('Taxi.ipynb')\n",
    "    \n",
    "    ex.groundClient('ground')\n",
    "\n",
    "    tr_data = ex.artifact('train_df.csv')\n",
    "\n",
    "    tr_data2 = ex.artifact('train.csv')\n",
    "\n",
    "    te_data = ex.artifact('test_df.csv')\n",
    "\n",
    "    @jarvis.func\n",
    "    def dataframize(csvpath):\n",
    "        import pandas as pd\n",
    "        return pd.read_csv(csvpath)\n",
    "\n",
    "\n",
    "    do_dfize = ex.action(dataframize, [tr_data])\n",
    "\n",
    "    tr_data_df = ex.artifact('train_df.pkl', do_dfize)\n",
    "\n",
    "    @jarvis.func\n",
    "    def calculate_distance(data_df):\n",
    "        def manhattan_distance(x1, y1, x2, y2):\n",
    "            return abs(x1 - x2) + abs(y1 - y2)\n",
    "        data_df['distance'] = [ i for i in map(manhattan_distance, data_df['pickup_longitude'], data_df['pickup_latitude'], \n",
    "                                               data_df['dropoff_longitude'], data_df['dropoff_latitude'])]\n",
    "        return data_df\n",
    "\n",
    "    # Trimmed some Notebook Cells without losing the log.\n",
    "\n",
    "    # Other thing with Nb. variables continue to exist even after cell has been clipped.\n",
    "\n",
    "    do_calc_dist = ex.action(calculate_distance, [tr_data_df])\n",
    "    tr_data_dist_df = ex.artifact('train_dist_df.pkl', do_calc_dist)\n",
    "\n",
    "    @jarvis.func\n",
    "    def preproc(train_data):\n",
    "        import numpy as np\n",
    "        # https://www.kaggle.com/stephaniestallworth/nyc-taxi-eda-regression-fivethirtyeight-viz/notebook\n",
    "        train_data = train_data[train_data['passenger_count']>0]\n",
    "        train_data = train_data[train_data['passenger_count']<9]\n",
    "\n",
    "        # Remove coordinate outliers\n",
    "        train_data = train_data[train_data['pickup_longitude'] <= -73.75]\n",
    "        train_data = train_data[train_data['pickup_longitude'] >= -74.03]\n",
    "        train_data = train_data[train_data['pickup_latitude'] <= 40.85]\n",
    "        train_data = train_data[train_data['pickup_latitude'] >= 40.63]\n",
    "        train_data = train_data[train_data['dropoff_longitude'] <= -73.75]\n",
    "        train_data = train_data[train_data['dropoff_longitude'] >= -74.03]\n",
    "        train_data = train_data[train_data['dropoff_latitude'] <= 40.85]\n",
    "        train_data = train_data[train_data['dropoff_latitude'] >= 40.63]\n",
    "\n",
    "        # Remove trip_duration outliers\n",
    "        trip_duration_mean = np.mean(train_data['trip_duration'])\n",
    "        trip_duration_std = np.std(train_data['trip_duration'])\n",
    "        train_data = train_data[train_data['trip_duration']<=trip_duration_mean + 2*trip_duration_std]\n",
    "        train_data = train_data[train_data['trip_duration']>= trip_duration_mean - 2*trip_duration_std]\n",
    "        train_data = train_data[train_data['trip_duration'] >= 30]\n",
    "        train_data = train_data[train_data['trip_duration'] <= 60*240]\n",
    "\n",
    "        return train_data\n",
    "\n",
    "    do_preproc = ex.action(preproc, [tr_data_dist_df])\n",
    "    tr_ready = ex.artifact('train_ready.pkl', do_preproc)\n",
    "\n",
    "    @jarvis.func\n",
    "    def split(data_df):\n",
    "        X = data_df[['vendor_id', 'passenger_count', 'pickup_longitude',\n",
    "            'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "           'store_and_fwd_flag', 'pickup_datetime', 'distance']]\n",
    "        y = data_df['trip_duration']\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    do_split = ex.action(split, [tr_ready])\n",
    "    xTrain = ex.artifact('xTrain.pkl', do_split)\n",
    "    xTest = ex.artifact('xTest.pkl', do_split)\n",
    "    yTrain = ex.artifact('yTrain.pkl', do_split)\n",
    "    yTest = ex.artifact('yTest.pkl', do_split)\n",
    "\n",
    "    @jarvis.func\n",
    "    def train(data_df, trainingy):\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "        data_df['duration'] = trainingy\n",
    "\n",
    "        def roundtime(tstring):\n",
    "            hours, mins, secs = tstring.split(':')\n",
    "            if int(mins) >= 30:\n",
    "                if hours == '23':\n",
    "                    return '00'\n",
    "                else:\n",
    "                    return str(int(hours) + 1)\n",
    "            else:\n",
    "                return hours\n",
    "\n",
    "        def weekday(start):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp = datetime.strptime(start, fmt)\n",
    "            return int(tstamp.weekday())\n",
    "\n",
    "        data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "        data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "        data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "        import math\n",
    "\n",
    "        clf = RandomForestRegressor(n_estimators=20, n_jobs=3)\n",
    "        #clf = LinearRegression()\n",
    "        scaler = StandardScaler()\n",
    "        # Scaler does not help\n",
    "        #scaler.fit(data_df[['vendor_id', 'start_hr', 'start_month', 'start_weekday', 'distance']].values)\n",
    "        clf.fit(data_df[['vendor_id', 'start_hr', 'start_month', 'start_weekday', 'distance', \n",
    "                         'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "                        'dropoff_latitude']].values, data_df['duration'].values )\n",
    "        return clf, scaler\n",
    "\n",
    "    do_train = ex.action(train, [xTrain, yTrain])\n",
    "    model = ex.artifact('model.pkl', do_train)\n",
    "    scaler = ex.artifact('scaler.pkl', do_train)\n",
    "\n",
    "    do_te_dfize = ex.action(dataframize, [te_data])\n",
    "    te_data_df = ex.artifact('test_df.pkl', do_te_dfize)\n",
    "\n",
    "    do_te_calcdist = ex.action(calculate_distance, [te_data_df])\n",
    "    te_data_dist_df = ex.artifact('test_dist_df.pkl', do_te_calcdist)\n",
    "\n",
    "    @jarvis.func\n",
    "    def calculate_duration(data_df):\n",
    "        def tdiff(start, end):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp1 = datetime.strptime(start, fmt)\n",
    "            tstamp2 = datetime.strptime(end, fmt)\n",
    "\n",
    "            if tstamp1 > tstamp2:\n",
    "                td = tstamp1 - tstamp2\n",
    "            else:\n",
    "                td = tstamp2 - tstamp1\n",
    "            return int(td.total_seconds())\n",
    "        data_df['duration'] = [i for i in map(tdiff, data_df['pickup_datetime'], data_df['dropoff_datetime'])]\n",
    "        return data_df\n",
    "\n",
    "\n",
    "\n",
    "    do_te_calcdur = ex.action(calculate_duration, [te_data_dist_df])\n",
    "    te_data_full_df = ex.artifact('test_dist_dur_df.pkl', do_te_calcdur)\n",
    "\n",
    "    @jarvis.func\n",
    "    def test(model, data_df, testingy, scaler):\n",
    "        import numpy as np\n",
    "        data_df['duration'] = testingy\n",
    "        def roundtime(tstring):\n",
    "            hours, mins, secs = tstring.split(':')\n",
    "            if int(mins) >= 30:\n",
    "                if hours == '23':\n",
    "                    return '00'\n",
    "                else:\n",
    "                    return str(int(hours) + 1)\n",
    "            else:\n",
    "                return hours\n",
    "        def weekday(start):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp = datetime.strptime(start, fmt)\n",
    "            return int(tstamp.weekday())\n",
    "\n",
    "        data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "        data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "        data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "\n",
    "        preds = model.predict(data_df[['vendor_id', 'start_hr', 'start_month', 'start_weekday', 'distance', \n",
    "                         'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "                        'dropoff_latitude']].values)\n",
    "        from sklearn import metrics\n",
    "        import math\n",
    "        score = metrics.explained_variance_score(data_df['duration'].values, preds)\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(data_df['duration'].values, preds))\n",
    "        return str(score) + '\\n' + str(rmse)\n",
    "\n",
    "\n",
    "    do_test = ex.action(test, [model, xTest, yTest, scaler])\n",
    "    score = ex.artifact('score.txt', do_test)\n",
    "\n",
    "    @jarvis.func\n",
    "    def comp_predictions(model, data_df, scaler):\n",
    "        def roundtime(tstring):\n",
    "            hours, mins, secs = tstring.split(':')\n",
    "            if int(mins) >= 30:\n",
    "                if hours == '23':\n",
    "                    return '00'\n",
    "                else:\n",
    "                    return str(int(hours) + 1)\n",
    "            else:\n",
    "                return hours\n",
    "        def weekday(start):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp = datetime.strptime(start, fmt)\n",
    "            return int(tstamp.weekday())\n",
    "\n",
    "        data_df['start_hr'] = data_df['start_timestamp'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "        data_df['start_month'] = data_df['start_timestamp'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "        data_df['start_weekday']= data_df['start_timestamp'].apply(lambda x: weekday(x))\n",
    "\n",
    "        predictions = (model.predict(data_df[['start_hr', 'start_month', 'start_weekday', 'distance']].values), data_df['duration'])\n",
    "        return predictions\n",
    "\n",
    "    do_comp = ex.action(comp_predictions, [model, te_data_full_df, scaler])\n",
    "    preds = ex.artifact('predictions.pkl', do_comp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id,vendor_id,start_timestamp,end_timestamp,passenger_count,start_lng,start_lat,end_lng,end_lat,store_and_fwd_flag,duration\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data.peek(head=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id,vendor_id,pickup_datetime,dropoff_datetime,passenger_count,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,store_and_fwd_flag,trip_duration\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data2.peek(head=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
