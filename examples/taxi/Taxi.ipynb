{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxi: Predict Trip Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a pipeline that predicts the trip duration from attributes such as pickup location, distance traveled, time of day, and so on. This pipeline is a typical ML workflow written in Python, using Scikit-learn (RandomForrest). We see pre-processing, training, and testing steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/stephaniestallworth/nyc-taxi-eda-regression-fivethirtyeight-viz/notebook\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def manhattan_distance(x1, y1, x2, y2):\n",
    "    return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "def roundtime(tstring):\n",
    "    hours, mins, secs = tstring.split(':')\n",
    "    if int(mins) >= 30:\n",
    "        if hours == '23':\n",
    "            return '00'\n",
    "        else:\n",
    "            return str(int(hours) + 1)\n",
    "    else:\n",
    "        return hours\n",
    "\n",
    "def weekday(start):\n",
    "    from datetime import datetime\n",
    "    fmt = '%Y-%m-%d %H:%M:%S'\n",
    "    tstamp = datetime.strptime(start, fmt)\n",
    "    return int(tstamp.weekday())\n",
    "\n",
    "data_df = pd.read_csv('train.csv')\n",
    "\n",
    "data_df['distance'] = [i for i in map(manhattan_distance,\n",
    "    data_df['pickup_longitude'], data_df['pickup_latitude'], \n",
    "    data_df['dropoff_longitude'], data_df['dropoff_latitude'])]\n",
    "\n",
    "# Remove outliers in passenger_count\n",
    "data_df = data_df[data_df['passenger_count']>0]\n",
    "data_df = data_df[data_df['passenger_count']<9]\n",
    "\n",
    "# Remove coordinate outliers\n",
    "data_df = data_df[data_df['pickup_longitude'] <= -73.75]\n",
    "data_df = data_df[data_df['pickup_longitude'] >= -74.03]\n",
    "data_df = data_df[data_df['pickup_latitude'] <= 40.85]\n",
    "data_df = data_df[data_df['pickup_latitude'] >= 40.63]\n",
    "data_df = data_df[data_df['dropoff_longitude'] <= -73.75]\n",
    "data_df = data_df[data_df['dropoff_longitude'] >= -74.03]\n",
    "data_df = data_df[data_df['dropoff_latitude'] <= 40.85]\n",
    "data_df = data_df[data_df['dropoff_latitude'] >= 40.63]\n",
    "\n",
    "# Remove trip_duration outliers\n",
    "trip_duration_mean = np.mean(data_df['trip_duration'])\n",
    "trip_duration_std = np.std(data_df['trip_duration'])\n",
    "data_df = data_df[data_df['trip_duration'] <= trip_duration_mean + 2*trip_duration_std]\n",
    "data_df = data_df[data_df['trip_duration'] >= trip_duration_mean - 2*trip_duration_std]\n",
    "data_df = data_df[data_df['trip_duration'] >= 30]\n",
    "data_df = data_df[data_df['trip_duration'] <= 60*240]\n",
    "\n",
    "data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "X = data_df[['vendor_id', 'pickup_longitude',\n",
    "            'pickup_latitude', 'dropoff_longitude', \n",
    "            'dropoff_latitude', 'distance',\n",
    "            'start_hr', 'start_month', 'start_weekday']]\n",
    "y = data_df['trip_duration']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "    y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=20, n_jobs=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "score = metrics.explained_variance_score(y_test, preds)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "\n",
    "print(\"R2: {}\".format(score))\n",
    "print(\"RMSE: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarsest Jarvis Pipeline: Wrap an existing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect many of our users to already have pipelines that they built and refined over time. We expect our users to trust these pipelines, and these pipelines to be effective. For such users, we add value by versioning the artifacts the user wants us to track, as well as recording the relationships between some objects at a corase level. To wrap an existing pipeline in Jarvis, simply put the pipeline code inside a decorated function, and tell us what the inputs and outputs of the function are. Please see example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jarvis\n",
    "\n",
    "with jarvis.Experiment('coarsest') as ex:\n",
    "    \n",
    "    jarvis.setNotebookName('Taxi.ipynb')\n",
    "    ex.groundClient('ground')\n",
    "    \n",
    "    @jarvis.func\n",
    "    def run_existing_pipeline(path_to_data):\n",
    "        import math\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        from sklearn import metrics\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        from sklearn.model_selection import train_test_split\n",
    "    \n",
    "        def manhattan_distance(x1, y1, x2, y2):\n",
    "            return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "        def roundtime(tstring):\n",
    "            hours, mins, secs = tstring.split(':')\n",
    "            if int(mins) >= 30:\n",
    "                if hours == '23':\n",
    "                    return '00'\n",
    "                else:\n",
    "                    return str(int(hours) + 1)\n",
    "            else:\n",
    "                return hours\n",
    "\n",
    "        def weekday(start):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp = datetime.strptime(start, fmt)\n",
    "            return int(tstamp.weekday())\n",
    "\n",
    "        data_df = pd.read_csv(path_to_data)\n",
    "\n",
    "        data_df['distance'] = [i for i in map(manhattan_distance,\n",
    "            data_df['pickup_longitude'], data_df['pickup_latitude'], \n",
    "            data_df['dropoff_longitude'], data_df['dropoff_latitude'])]\n",
    "\n",
    "        # Remove outliers in passenger_count\n",
    "        data_df = data_df[data_df['passenger_count']>0]\n",
    "        data_df = data_df[data_df['passenger_count']<9]\n",
    "\n",
    "        # Remove coordinate outliers\n",
    "        data_df = data_df[data_df['pickup_longitude'] <= -73.75]\n",
    "        data_df = data_df[data_df['pickup_longitude'] >= -74.03]\n",
    "        data_df = data_df[data_df['pickup_latitude'] <= 40.85]\n",
    "        data_df = data_df[data_df['pickup_latitude'] >= 40.63]\n",
    "        data_df = data_df[data_df['dropoff_longitude'] <= -73.75]\n",
    "        data_df = data_df[data_df['dropoff_longitude'] >= -74.03]\n",
    "        data_df = data_df[data_df['dropoff_latitude'] <= 40.85]\n",
    "        data_df = data_df[data_df['dropoff_latitude'] >= 40.63]\n",
    "\n",
    "        # Remove trip_duration outliers\n",
    "        trip_duration_mean = np.mean(data_df['trip_duration'])\n",
    "        trip_duration_std = np.std(data_df['trip_duration'])\n",
    "        data_df = data_df[data_df['trip_duration'] <= trip_duration_mean + 2*trip_duration_std]\n",
    "        data_df = data_df[data_df['trip_duration'] >= trip_duration_mean - 2*trip_duration_std]\n",
    "        data_df = data_df[data_df['trip_duration'] >= 30]\n",
    "        data_df = data_df[data_df['trip_duration'] <= 60*240]\n",
    "\n",
    "        data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "        data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "        data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "        X = data_df[['vendor_id', 'pickup_longitude',\n",
    "                    'pickup_latitude', 'dropoff_longitude', \n",
    "                    'dropoff_latitude', 'distance',\n",
    "                    'start_hr', 'start_month', 'start_weekday']]\n",
    "        y = data_df['trip_duration']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "            y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "        clf = RandomForestRegressor(n_estimators=20, n_jobs=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        preds = clf.predict(X_test)\n",
    "        score = metrics.explained_variance_score(y_test, preds)\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "\n",
    "        score = \"R2: {}\".format(score)\n",
    "        rmse = \"RMSE: {}\".format(rmse)\n",
    "        \n",
    "        print(score, rmse)\n",
    "    \n",
    "        return clf, score, rmse\n",
    "    \n",
    "    data = ex.artifact('train.csv')\n",
    "    do_all = ex.action(run_existing_pipeline, [data])\n",
    "    model = ex.artifact('model.pkl', do_all)\n",
    "    score = ex.artifact('score.txt', do_all)\n",
    "    rmse = ex.artifact('rmse.txt', do_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarse Jarvis Pipeline with Hyper-parameter Sweeps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe after some time, a trusted and effective pipeline may need some tuning. We enable pipeline (and model) tuning via Jarvis Literals. A user can declare a Literal, with some iterable value or any Python basic type. When a literal is passed to an Action, the experiment may become a multi-trial experiment. Jarvis is able to execute every trial with some optimizations, and relate the experiment outcomes to the experiment configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jarvis\n",
    "\n",
    "with jarvis.Experiment('coarse') as ex:\n",
    "    import math\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn import metrics\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    jarvis.setNotebookName('Taxi.ipynb')\n",
    "    ex.groundClient('ground')\n",
    "    \n",
    "    @jarvis.func\n",
    "    def run_existing_pipeline(path_to_data, n_estimators):\n",
    "    \n",
    "        def manhattan_distance(x1, y1, x2, y2):\n",
    "            return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "        def roundtime(tstring):\n",
    "            hours, mins, secs = tstring.split(':')\n",
    "            if int(mins) >= 30:\n",
    "                if hours == '23':\n",
    "                    return '00'\n",
    "                else:\n",
    "                    return str(int(hours) + 1)\n",
    "            else:\n",
    "                return hours\n",
    "\n",
    "        def weekday(start):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp = datetime.strptime(start, fmt)\n",
    "            return int(tstamp.weekday())\n",
    "\n",
    "        data_df = pd.read_csv(path_to_data)\n",
    "\n",
    "        data_df['distance'] = [i for i in map(manhattan_distance,\n",
    "            data_df['pickup_longitude'], data_df['pickup_latitude'], \n",
    "            data_df['dropoff_longitude'], data_df['dropoff_latitude'])]\n",
    "\n",
    "        # Remove outliers in passenger_count\n",
    "        data_df = data_df[data_df['passenger_count']>0]\n",
    "        data_df = data_df[data_df['passenger_count']<9]\n",
    "\n",
    "        # Remove coordinate outliers\n",
    "        data_df = data_df[data_df['pickup_longitude'] <= -73.75]\n",
    "        data_df = data_df[data_df['pickup_longitude'] >= -74.03]\n",
    "        data_df = data_df[data_df['pickup_latitude'] <= 40.85]\n",
    "        data_df = data_df[data_df['pickup_latitude'] >= 40.63]\n",
    "        data_df = data_df[data_df['dropoff_longitude'] <= -73.75]\n",
    "        data_df = data_df[data_df['dropoff_longitude'] >= -74.03]\n",
    "        data_df = data_df[data_df['dropoff_latitude'] <= 40.85]\n",
    "        data_df = data_df[data_df['dropoff_latitude'] >= 40.63]\n",
    "\n",
    "        # Remove trip_duration outliers\n",
    "        trip_duration_mean = np.mean(data_df['trip_duration'])\n",
    "        trip_duration_std = np.std(data_df['trip_duration'])\n",
    "        data_df = data_df[data_df['trip_duration'] <= trip_duration_mean + 2*trip_duration_std]\n",
    "        data_df = data_df[data_df['trip_duration'] >= trip_duration_mean - 2*trip_duration_std]\n",
    "        data_df = data_df[data_df['trip_duration'] >= 30]\n",
    "        data_df = data_df[data_df['trip_duration'] <= 60*240]\n",
    "\n",
    "        data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "        data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "        data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "        X = data_df[['vendor_id', 'pickup_longitude',\n",
    "                    'pickup_latitude', 'dropoff_longitude', \n",
    "                    'dropoff_latitude', 'distance',\n",
    "                    'start_hr', 'start_month', 'start_weekday']]\n",
    "        y = data_df['trip_duration']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "            y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "        clf = RandomForestRegressor(n_estimators=n_estimators, n_jobs=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        preds = clf.predict(X_test)\n",
    "        score = metrics.explained_variance_score(y_test, preds)\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "\n",
    "        score = \"R2: {}\".format(score)\n",
    "        rmse = \"RMSE: {}\".format(rmse)\n",
    "        \n",
    "        print(score, rmse)\n",
    "    \n",
    "        return clf, score, rmse\n",
    "    \n",
    "    data = ex.artifact('train.csv')\n",
    "    num_est = ex.literal([15, 20, 30], 'num_estimators')\n",
    "    num_est.forEach()\n",
    "    do_all = ex.action(run_existing_pipeline, [data, num_est])\n",
    "    model = ex.artifact('model.pkl', do_all)\n",
    "    score = ex.artifact('score.txt', do_all)\n",
    "    rmse = ex.artifact('rmse.txt', do_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Jarvis Pipeline: Reuse Intermediate Artifacts & Compose Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps our user will observe that the preprocessing step produces a result that can be shared with the entire organization; alteranively, it's possible that the pre-processing step is expensive, and the user will not want to re-run this step every time that the system runs the pipeline with a new configuration (caching intermediate shared results). A subgraph in the Jarvis pipeline may be its own experiment, or part of a parent experiment. When the Jarvis pipeline is shared with others (as opposed to merely sharing the end results), it's possible for other users or customers of the data to understand the lineage of the results: what transformations were applied, and what the source was, etc. We include an example below for how a user might separete the preprocessing step from the remaining pipeline, so that the subpipeline may be more easily shared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import jarvis\n",
    "\n",
    "with jarvis.Experiment('fine') as ex:\n",
    "    \n",
    "    jarvis.setNotebookName('Taxi.ipynb')\n",
    "    ex.groundClient('ground')\n",
    "    \n",
    "    @jarvis.func\n",
    "    def prepare_data(path_to_data):\n",
    "    \n",
    "        def manhattan_distance(x1, y1, x2, y2):\n",
    "            return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "        def roundtime(tstring):\n",
    "            hours, mins, secs = tstring.split(':')\n",
    "            if int(mins) >= 30:\n",
    "                if hours == '23':\n",
    "                    return '00'\n",
    "                else:\n",
    "                    return str(int(hours) + 1)\n",
    "            else:\n",
    "                return hours\n",
    "\n",
    "        def weekday(start):\n",
    "            from datetime import datetime\n",
    "            fmt = '%Y-%m-%d %H:%M:%S'\n",
    "            tstamp = datetime.strptime(start, fmt)\n",
    "            return int(tstamp.weekday())\n",
    "\n",
    "        data_df = pd.read_csv(path_to_data)\n",
    "\n",
    "        data_df['distance'] = [i for i in map(manhattan_distance,\n",
    "            data_df['pickup_longitude'], data_df['pickup_latitude'], \n",
    "            data_df['dropoff_longitude'], data_df['dropoff_latitude'])]\n",
    "\n",
    "        # Remove outliers in passenger_count\n",
    "        data_df = data_df[data_df['passenger_count']>0]\n",
    "        data_df = data_df[data_df['passenger_count']<9]\n",
    "\n",
    "        # Remove coordinate outliers\n",
    "        data_df = data_df[data_df['pickup_longitude'] <= -73.75]\n",
    "        data_df = data_df[data_df['pickup_longitude'] >= -74.03]\n",
    "        data_df = data_df[data_df['pickup_latitude'] <= 40.85]\n",
    "        data_df = data_df[data_df['pickup_latitude'] >= 40.63]\n",
    "        data_df = data_df[data_df['dropoff_longitude'] <= -73.75]\n",
    "        data_df = data_df[data_df['dropoff_longitude'] >= -74.03]\n",
    "        data_df = data_df[data_df['dropoff_latitude'] <= 40.85]\n",
    "        data_df = data_df[data_df['dropoff_latitude'] >= 40.63]\n",
    "\n",
    "        # Remove trip_duration outliers\n",
    "        trip_duration_mean = np.mean(data_df['trip_duration'])\n",
    "        trip_duration_std = np.std(data_df['trip_duration'])\n",
    "        data_df = data_df[data_df['trip_duration'] <= trip_duration_mean + 2*trip_duration_std]\n",
    "        data_df = data_df[data_df['trip_duration'] >= trip_duration_mean - 2*trip_duration_std]\n",
    "        data_df = data_df[data_df['trip_duration'] >= 30]\n",
    "        data_df = data_df[data_df['trip_duration'] <= 60*240]\n",
    "\n",
    "        data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "        data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "        data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "        return data_df\n",
    "    \n",
    "    @jarvis.func\n",
    "    def train_test_model(data_df, n_estimators):\n",
    "        X = data_df[['vendor_id', 'pickup_longitude',\n",
    "                    'pickup_latitude', 'dropoff_longitude', \n",
    "                    'dropoff_latitude', 'distance',\n",
    "                    'start_hr', 'start_month', 'start_weekday']]\n",
    "        y = data_df['trip_duration']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "            y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "        clf = RandomForestRegressor(n_estimators=n_estimators, n_jobs=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        preds = clf.predict(X_test)\n",
    "        score = metrics.explained_variance_score(y_test, preds)\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "\n",
    "        score = \"R2: {}\".format(score)\n",
    "        rmse = \"RMSE: {}\".format(rmse)\n",
    "        \n",
    "        print(score, rmse)\n",
    "    \n",
    "        return clf, score, rmse\n",
    "    \n",
    "    data = ex.artifact('train.csv')\n",
    "    num_est = ex.literal([15, 20, 30], 'num_estimators')\n",
    "    num_est.forEach()\n",
    "    \n",
    "    do_prep = ex.action(prepare_data, [data])\n",
    "    prepd = ex.artifact('prepped_data.pkl', do_prep)\n",
    "    \n",
    "    do_tr_te = ex.action(train_test_model, [prepd, num_est])\n",
    "\n",
    "    \n",
    "    model = ex.artifact('model.pkl', do_tr_te)\n",
    "    score = ex.artifact('score.txt', do_tr_te)\n",
    "    rmse = ex.artifact('rmse.txt', do_tr_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finest Pipeline: Jarvis Proper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After becoming familiar with Jarvis, it is likely that our user will want to build her next pipeline using Jarvis from the start: this was the use-case we envisioed at first. In addition to gaining the benefits from coarser Jarvis pipelines, the user will be given a set of tools for pipeline development in an interactive environment such as Jupyter. We are currently investigating techniques for detecting poor experiment methods, such as p-hacking or data dredging. Whenever a user \"peeks\" a Jarvis artifact, the event is recorded. We plan to use this information to infer when information from the test data may have been compromised and contaminated the analysis, and when it's likely that the user has overfitted to the data, and it's time to collect a fresh sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jarvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jarvis.setNotebookName('Taxi.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = jarvis.Experiment('finest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.groundClient('ground')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ex.artifact('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jarvis.func\n",
    "def dataframize(csvpath):\n",
    "    import pandas as pd\n",
    "    return pd.read_csv(csvpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_dfize = ex.action(dataframize, [data])\n",
    "tr_data_df = ex.artifact('train_df.pkl', do_dfize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of *peek*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_df.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jarvis.func\n",
    "def calculate_distance(data_df):\n",
    "    def manhattan_distance(x1, y1, x2, y2):\n",
    "        return abs(x1 - x2) + abs(y1 - y2)\n",
    "    data_df['distance'] = [ i for i in map(manhattan_distance, data_df['pickup_longitude'], data_df['pickup_latitude'], \n",
    "                                           data_df['dropoff_longitude'], data_df['dropoff_latitude'])]\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_calc_dist = ex.action(calculate_distance, [tr_data_df])\n",
    "tr_data_dist_df = ex.artifact('train_dist_df.pkl', do_calc_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jarvis.func\n",
    "def preproc(train_data):\n",
    "    import numpy as np\n",
    "    # https://www.kaggle.com/stephaniestallworth/nyc-taxi-eda-regression-fivethirtyeight-viz/notebook\n",
    "    train_data = train_data[train_data['passenger_count']>0]\n",
    "    train_data = train_data[train_data['passenger_count']<9]\n",
    "\n",
    "    # Remove coordinate outliers\n",
    "    train_data = train_data[train_data['pickup_longitude'] <= -73.75]\n",
    "    train_data = train_data[train_data['pickup_longitude'] >= -74.03]\n",
    "    train_data = train_data[train_data['pickup_latitude'] <= 40.85]\n",
    "    train_data = train_data[train_data['pickup_latitude'] >= 40.63]\n",
    "    train_data = train_data[train_data['dropoff_longitude'] <= -73.75]\n",
    "    train_data = train_data[train_data['dropoff_longitude'] >= -74.03]\n",
    "    train_data = train_data[train_data['dropoff_latitude'] <= 40.85]\n",
    "    train_data = train_data[train_data['dropoff_latitude'] >= 40.63]\n",
    "\n",
    "    # Remove trip_duration outliers\n",
    "    trip_duration_mean = np.mean(train_data['trip_duration'])\n",
    "    trip_duration_std = np.std(train_data['trip_duration'])\n",
    "    train_data = train_data[train_data['trip_duration']<=trip_duration_mean + 2*trip_duration_std]\n",
    "    train_data = train_data[train_data['trip_duration']>= trip_duration_mean - 2*trip_duration_std]\n",
    "    train_data = train_data[train_data['trip_duration'] >= 30]\n",
    "    train_data = train_data[train_data['trip_duration'] <= 60*240]\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_preproc = ex.action(preproc, [tr_data_dist_df])\n",
    "tr_ready = ex.artifact('train_ready.pkl', do_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jarvis.func\n",
    "def split(data_df):\n",
    "    X = data_df[['vendor_id', 'passenger_count', 'pickup_longitude',\n",
    "        'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "       'store_and_fwd_flag', 'pickup_datetime', 'distance']]\n",
    "    y = data_df['trip_duration']\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_split = ex.action(split, [tr_ready])\n",
    "xTrain = ex.artifact('xTrain.pkl', do_split)\n",
    "xTest = ex.artifact('xTest.pkl', do_split)\n",
    "yTrain = ex.artifact('yTrain.pkl', do_split)\n",
    "yTest = ex.artifact('yTest.pkl', do_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jarvis.func\n",
    "def train(data_df, trainingy, num_estimators):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    data_df['duration'] = trainingy\n",
    "\n",
    "    def roundtime(tstring):\n",
    "        hours, mins, secs = tstring.split(':')\n",
    "        if int(mins) >= 30:\n",
    "            if hours == '23':\n",
    "                return '00'\n",
    "            else:\n",
    "                return str(int(hours) + 1)\n",
    "        else:\n",
    "            return hours\n",
    "\n",
    "    def weekday(start):\n",
    "        from datetime import datetime\n",
    "        fmt = '%Y-%m-%d %H:%M:%S'\n",
    "        tstamp = datetime.strptime(start, fmt)\n",
    "        return int(tstamp.weekday())\n",
    "\n",
    "    data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "    data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "    data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "    import math\n",
    "\n",
    "    clf = RandomForestRegressor(n_estimators=20, n_jobs=3)\n",
    "    clf.fit(data_df[['vendor_id', 'start_hr', 'start_month', 'start_weekday', 'distance', \n",
    "                     'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "                    'dropoff_latitude']].values, data_df['duration'].values )\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_est = ex.literal([15, 20, 30], \"num_estimators\")\n",
    "num_est.forEach()\n",
    "do_train = ex.action(train, [xTrain, yTrain, num_est])\n",
    "model = ex.artifact('model.pkl', do_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jarvis.func\n",
    "def test(model, data_df, testingy):\n",
    "    import numpy as np\n",
    "    data_df['duration'] = testingy\n",
    "    def roundtime(tstring):\n",
    "        hours, mins, secs = tstring.split(':')\n",
    "        if int(mins) >= 30:\n",
    "            if hours == '23':\n",
    "                return '00'\n",
    "            else:\n",
    "                return str(int(hours) + 1)\n",
    "        else:\n",
    "            return hours\n",
    "    def weekday(start):\n",
    "        from datetime import datetime\n",
    "        fmt = '%Y-%m-%d %H:%M:%S'\n",
    "        tstamp = datetime.strptime(start, fmt)\n",
    "        return int(tstamp.weekday())\n",
    "\n",
    "    data_df['start_hr'] = data_df['pickup_datetime'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "    data_df['start_month'] = data_df['pickup_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "    data_df['start_weekday']= data_df['pickup_datetime'].apply(lambda x: weekday(x))\n",
    "\n",
    "\n",
    "    preds = model.predict(data_df[['vendor_id', 'start_hr', 'start_month', 'start_weekday', 'distance', \n",
    "                     'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "                    'dropoff_latitude']].values)\n",
    "    from sklearn import metrics\n",
    "    import math\n",
    "    score = metrics.explained_variance_score(data_df['duration'].values, preds)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(data_df['duration'].values, preds))\n",
    "    return str(score), str(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_test = ex.action(test, [model, xTest, yTest])\n",
    "score = ex.artifact('score.txt', do_test)\n",
    "rmse = ex.artifact('rmse.txt', do_test)\n",
    "ex.__exit__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
