{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jarvis\n",
    "\n",
    "ex = jarvis.Experiment('taxi')\n",
    "ex.groundClient('ground')\n",
    "\n",
    "tr_data = ex.artifact('train_df.csv')\n",
    "\n",
    "te_data = ex.artifact('test_df.csv')\n",
    "\n",
    "# What model should I use to predict the duration of a car ride? Idk... try many of them?\n",
    "\n",
    "# look at the data that I have\n",
    "\n",
    "# The duration of the cab ride depends on the distance and time of day.\n",
    "\n",
    "# Feature engineering step: get manhattan distance from coordinates start to coordinates end\n",
    "\n",
    "# But first, let's get the data into a format that's easy to work with\n",
    "\n",
    "#Forgot to set the name!\n",
    "jarvis.setNotebookName('Taxi.ipynb')\n",
    "\n",
    "@jarvis.func\n",
    "def dataframize(csvpath):\n",
    "    import pandas as pd\n",
    "    return pd.read_csv(csvpath)\n",
    "\n",
    "\n",
    "do_dfize = ex.action(dataframize, [tr_data])\n",
    "\n",
    "tr_data_df = ex.artifact('train_df.pkl', do_dfize)\n",
    "\n",
    "@jarvis.func\n",
    "def calculate_distance(data_df):\n",
    "    def manhattan_distance(x1, y1, x2, y2):\n",
    "        return abs(x1 - x2) + abs(y1 - y2)\n",
    "    data_df['distance'] = [ i for i in map(manhattan_distance, data_df['start_lng'], data_df['start_lat'], data_df['end_lng'], data_df['end_lat'])]\n",
    "    return data_df\n",
    "\n",
    "# Trimmed some Notebook Cells without losing the log.\n",
    "\n",
    "# Other thing with Nb. variables continue to exist even after cell has been clipped.\n",
    "\n",
    "do_calc_dist = ex.action(calculate_distance, [tr_data_df])\n",
    "tr_data_dist_df = ex.artifact('train_dist_df.pkl', do_calc_dist)\n",
    "\n",
    "@jarvis.func\n",
    "def preproc(train_data):\n",
    "    import numpy as np\n",
    "    # https://www.kaggle.com/stephaniestallworth/nyc-taxi-eda-regression-fivethirtyeight-viz/notebook\n",
    "    # Remove passenger_count outliers\n",
    "    train_data = train_data[train_data['passenger_count']>0]\n",
    "    train_data = train_data[train_data['passenger_count']<9]\n",
    "\n",
    "    # Remove coordinate outliers\n",
    "    train_data = train_data[train_data['start_lng'] <= -73.75]\n",
    "    train_data = train_data[train_data['start_lng'] >= -74.03]\n",
    "    train_data = train_data[train_data['start_lat'] <= 40.85]\n",
    "    train_data = train_data[train_data['start_lat'] >= 40.63]\n",
    "    train_data = train_data[train_data['end_lng'] <= -73.75]\n",
    "    train_data = train_data[train_data['end_lng'] >= -74.03]\n",
    "    train_data = train_data[train_data['end_lat'] <= 40.85]\n",
    "    train_data = train_data[train_data['end_lat'] >= 40.63]\n",
    "\n",
    "    # Remove trip_duration outliers\n",
    "    trip_duration_mean = np.mean(train_data['duration'])\n",
    "    trip_duration_std = np.std(train_data['duration'])\n",
    "    train_data = train_data[train_data['duration'] <= trip_duration_mean + 2*trip_duration_std]\n",
    "    train_data = train_data[train_data['duration'] >= trip_duration_mean - 2*trip_duration_std]\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "do_preproc = ex.action(preproc, [tr_data_dist_df])\n",
    "tr_ready = ex.artifact('train_ready.pkl', do_preproc)\n",
    "\n",
    "@jarvis.func\n",
    "def train(data_df):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "    def roundtime(tstring):\n",
    "        hours, mins, secs = tstring.split(':')\n",
    "        if int(mins) >= 30:\n",
    "            if hours == '23':\n",
    "                return '00'\n",
    "            else:\n",
    "                return str(int(hours) + 1)\n",
    "        else:\n",
    "            return hours\n",
    "    \n",
    "    def weekday(start):\n",
    "        from datetime import datetime\n",
    "        fmt = '%Y-%m-%d %H:%M:%S'\n",
    "        tstamp = datetime.strptime(start, fmt)\n",
    "        return int(tstamp.weekday())\n",
    "    \n",
    "    data_df['start_hr'] = data_df['start_timestamp'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "    data_df['start_month'] = data_df['start_timestamp'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "    data_df['start_weekday']= data_df['start_timestamp'].apply(lambda x: weekday(x))\n",
    "    \n",
    "    #clf = RandomForestRegressor(n_estimators=20)\n",
    "    clf = LinearRegression()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data_df[['start_hr', 'start_month', 'start_weekday', 'distance']].values)\n",
    "    clf.fit(data_df[['start_hr', 'start_month', 'start_weekday', 'distance']].values, data_df['duration'].values )\n",
    "    return clf, scaler\n",
    "\n",
    "do_train = ex.action(train, [tr_ready])\n",
    "model = ex.artifact('model.pkl', do_train)\n",
    "scaler = ex.artifact('scaler.pkl', do_train)\n",
    "\n",
    "do_te_dfize = ex.action(dataframize, [te_data])\n",
    "te_data_df = ex.artifact('test_df.pkl', do_te_dfize)\n",
    "\n",
    "do_te_calcdist = ex.action(calculate_distance, [te_data_df])\n",
    "te_data_dist_df = ex.artifact('test_dist_df.pkl', do_te_calcdist)\n",
    "\n",
    "@jarvis.func\n",
    "def calculate_duration(data_df):\n",
    "    def tdiff(start, end):\n",
    "        from datetime import datetime\n",
    "        fmt = '%Y-%m-%d %H:%M:%S'\n",
    "        tstamp1 = datetime.strptime(start, fmt)\n",
    "        tstamp2 = datetime.strptime(end, fmt)\n",
    "\n",
    "        if tstamp1 > tstamp2:\n",
    "            td = tstamp1 - tstamp2\n",
    "        else:\n",
    "            td = tstamp2 - tstamp1\n",
    "        return int(td.total_seconds())\n",
    "    data_df['duration'] = [i for i in map(tdiff, data_df['start_timestamp'], data_df['end_timestamp'])]\n",
    "    return data_df\n",
    "\n",
    "\n",
    "\n",
    "do_te_calcdur = ex.action(calculate_duration, [te_data_dist_df])\n",
    "te_data_full_df = ex.artifact('test_dist_dur_df.pkl', do_te_calcdur)\n",
    "\n",
    "@jarvis.func\n",
    "def test(model, data_df, scaler):\n",
    "    def roundtime(tstring):\n",
    "        hours, mins, secs = tstring.split(':')\n",
    "        if int(mins) >= 30:\n",
    "            if hours == '23':\n",
    "                return '00'\n",
    "            else:\n",
    "                return str(int(hours) + 1)\n",
    "        else:\n",
    "            return hours\n",
    "    def weekday(start):\n",
    "        from datetime import datetime\n",
    "        fmt = '%Y-%m-%d %H:%M:%S'\n",
    "        tstamp = datetime.strptime(start, fmt)\n",
    "        return int(tstamp.weekday())\n",
    "    \n",
    "    data_df['start_hr'] = data_df['start_timestamp'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "    data_df['start_month'] = data_df['start_timestamp'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "    data_df['start_weekday']= data_df['start_timestamp'].apply(lambda x: weekday(x))\n",
    "    \n",
    "    \n",
    "    preds = model.predict(data_df[['start_hr', 'start_month', 'start_weekday', 'distance']].values)\n",
    "    from sklearn import metrics\n",
    "    score = metrics.explained_variance_score(data_df['duration'].values, preds)\n",
    "    return score\n",
    "\n",
    "\n",
    "do_test = ex.action(test, [model, te_data_full_df, scaler])\n",
    "score = ex.artifact('score.txt', do_test)\n",
    "\n",
    "@jarvis.func\n",
    "def comp_predictions(model, data_df, scaler):\n",
    "    def roundtime(tstring):\n",
    "        hours, mins, secs = tstring.split(':')\n",
    "        if int(mins) >= 30:\n",
    "            if hours == '23':\n",
    "                return '00'\n",
    "            else:\n",
    "                return str(int(hours) + 1)\n",
    "        else:\n",
    "            return hours\n",
    "    def weekday(start):\n",
    "        from datetime import datetime\n",
    "        fmt = '%Y-%m-%d %H:%M:%S'\n",
    "        tstamp = datetime.strptime(start, fmt)\n",
    "        return int(tstamp.weekday())\n",
    "    \n",
    "    data_df['start_hr'] = data_df['start_timestamp'].apply(lambda x: int(roundtime(x.split(' ')[1])))\n",
    "    data_df['start_month'] = data_df['start_timestamp'].apply(lambda x: int(x.split(' ')[0].split('-')[1]))\n",
    "    data_df['start_weekday']= data_df['start_timestamp'].apply(lambda x: weekday(x))\n",
    "    \n",
    "    predictions = (model.predict(data_df[['start_hr', 'start_month', 'start_weekday', 'distance']].values), data_df['duration'])\n",
    "    return predictions\n",
    "\n",
    "do_comp = ex.action(comp_predictions, [model, te_data_full_df, scaler])\n",
    "preds = ex.artifact('predictions.pkl', do_comp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.00627427905862\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.peek()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
